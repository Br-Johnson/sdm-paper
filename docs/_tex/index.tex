% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={DRAFT Practical Data Stewardship for Salmon Biologists--A Blueprint for Domain-Specific Best Practices in Fisheries DRAFT},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{DRAFT Practical Data Stewardship for Salmon Biologists--A
Blueprint for Domain-Specific Best Practices in Fisheries DRAFT}
\author{Brett Johnson \and Scott Akenhead \and Katie
Barnas \and Jennifer Bayer \and Tomas Bird \and Samuel
Cimino \and Graeme Diack \and Lara Erikson \and Nancy
Leonard \and Catherine Michielsens \and Fiona Martens \and Emily
Lescak \and Gottfried Pestal \and Matt Jones \and Mark Saunders \and Yi
Xu}
\date{}
\begin{document}
\maketitle


\textbf{Keywords:} Salmon data stewardship, data interoperability, FAIR
principles, persistent identifiers (PIDs), controlled vocabularies,
metadata standards, application programming Interface (API), data
citation, ontology development

\subsubsection{Abstract}\label{abstract}

Fisheries research, management, and conservation increasingly generate
vast and diverse data crucial for timely decision-making. Yet these data
remain largely fragmented across jurisdictions, disciplines, and
outdated infrastructure, limiting their use in responsive management.
Biologists are increasingly taking on data stewardship responsibilities
to address these challenges, often without clear guidance, training, or
support. Shared, community-agreed practices for implementing
domain-specific data standards are needed to move beyond generic data
management guidance toward fit-for-purpose tools and workflows. To
address this gap---and to show how other communities can do so---we
develop seven practices for salmon data stewardship and demonstrate
their application through a real-world case study. We provide practical
guidance for those transitioning into these essential stewardship roles,
including domain-specific tools, templates, and examples from salmon
research and management. We argue that effective salmon management
depends on formally establishing data stewardship as a dedicated,
institutionally supported professional role. These practices integrate
both sociocultural and technical approaches to ensure data meet modern
open science principles and respect Indigenous Data Sovereignty. Through
a case study of a historical sockeye salmon productivity analysis
spanning Pacific Coast jurisdictions, we highlight how clearly defined
data stewardship practices enhance data reproducibility, integration,
and management efficacy. With a foundation of shared practices, data
stewards will enable faster, more transparent decision-making, support
development of machine-actionable datasets with high-quality metadata
and consistent semantics that enable automated analysis, and expand the
use of cross-jurisdictional datasets---ultimately strengthening the
management and conservation of salmon populations and the ecosystems
they inhabit, and, by extension, other data-rich fisheries data domains.

\subsection{The Data Stewardship
Challenge}\label{the-data-stewardship-challenge}

Integrated, timely, and high-quality data are essential for effective
fisheries research, management, and conservation. Such data underpin
robust stock assessments, inform adaptive management strategies, enable
rapid responses to emerging threats, and support transparent
decision-making. Yet across the fisheries domain, biologists face
persistent challenges in achieving these goals. Data on fish
populations, health, and environmental conditions are often fragmented,
inconsistently measured, and incomplete across time, space, and
life-history stages (NOAA Data Governance Committee 2024). These issues
limit the utility of these data for research and management.

\subsubsection{Cross-Jurisdictional Data
Fragmentation}\label{cross-jurisdictional-data-fragmentation}

The challenges are especially pronounced in salmon science, where data
must be integrated across multiple ecological regions and jurisdictional
boundaries (Groot and Margolis 1991). Salmon biologists routinely
collect information managed by diverse agencies and institutions, often
in isolation and without a focus on interoperability. While localized
successes in data coordination exist---particularly within regional
fisheries management offices and treaty commissions---salmon data
integrated across agencies for each phase of the salmon life cycle is
uncommon and costly for most programs (Marmorek et al. 2011; Inman et
al. 2021; Diack et al. 2024). Most salmon datasets remain confined
within institutional silos, often undocumented, stored in outdated
systems, or formatted according to internal standards that are
incompatible with broader integration efforts. Even within
organizations, data can be siloed by data type or program with
freshwater data going in one data system while estuary, open-ocean, and
commercial fishery data each housed in separate data systems with
limited ability to easily re-connect the data through shared
identifiers.

This fragmentation is compounded by the number of disciplines and
organizations involved. Geneticists, oceanographers, freshwater
ecologists, stock assessment biologists, and fisheries managers all
contribute data using their own field-specific conventions and
workflows. Meanwhile, data is distributed across federal, state,
provincial, tribal, and academic institutions---each with its own
mandates, technologies, and metadata requirements. Many salmon
data-holding organizations rely on aging infrastructure or opaque,
undocumented standards that lag behind modern open-science practices.
This tangle of disciplinary and institutional fragmentation slows
integration, hinders reproducibility, and delays analyses that could
otherwise inform time-sensitive management decisions, conservation
actions, or restoration plans. When critical datasets are hard to find,
access, or interpret, biologists and analysts lose valuable time trying
to reconstruct or harmonize them, reducing transparency, increasing the
risk of errors, and delaying urgent conservation or management
responses.

\subsubsection{The Need for Coordinated
Stewardship}\label{the-need-for-coordinated-stewardship}

The growing complexity of fisheries management, combined with escalating
environmental uncertainties due to climate change, demands rapid,
integrated, and robust data analyses (Bull et al. 2022,
ward\_surveyjoin\_2025). The mismatch between fragmented data systems
and fixed administrative boundaries creates an urgent need for
interoperable, dynamic, multi-scale data stewardship that can adapt to
shifting ecological and management priorities. Despite the scale and
importance of these datasets, biologists who collect and manage salmon
data are often expected to act as de facto data stewards without
training, guidance, institutional support, or access to community-agreed
best practices. Tasks such as documenting methods, aligning terminology,
formatting for data sharing, and publishing data are typically performed
off the side of a biologist's desk. A lack of institutional support
(Diack et al. 2024), training (Volk, Lucero, and Barnas 2014), and
dedicated roles for data management further relegate critical data
stewardship tasks to an \emph{ad hoc} status. The absence of clear
roles, standards, and community-endorsed practices leaves even motivated
scientists unsure how to structure their data for future use. As a
result, data stewardship is inconsistent and reactive, and data
integration remains a major bottleneck to adaptive management and
ecosystem-scale learning.

Both researchers and managers struggle to align their data with
community-agreed principles such as FAIR (Findable, Accessible,
Interoperable, and Reusable) (Wilkinson et al. 2016) and Indigenous Data
Sovereignty frameworks like the CARE principles (Collective Benefit,
Authority to Control, Responsibility, and Ethics) (Carroll,
Rodriguez-Lonebear, and Martinez 2019; Jennings et al. 2023). Adhering
to CARE data management principles is all the more important when it
comes to salmon related data given the sociocultural importance of
salmon to First Nations, Tribes, and Indigenous communities throughout
the North Pacific and North Atlantic regions (Ween and Colombi 2013;
Earth Economics 2021). Large volumes of data collected through long-term
monitoring programs hold tremendous value, especially for secondary
users---but are often inaccessible due to a lack of time, resources, and
incentives for data producers to publish them (LINDENMAYER et al. 2012).
Without clear support and guidance, well-intentioned practitioners are
left with ad hoc approaches that limit reuse and interoperability. This
gap can only be bridged by equipping both data producers and stewards
with tools, support, and institutional backing to publish interoperable,
machine-readable metadata and datasets in alignment with shared
principles.

\subsubsection{Framework for Action}\label{framework-for-action}

In this paper, we provide actionable practices, examples, and workflows
to help salmon biologists improve the usability, reproducibility, and
long-term impact of their data. We develop seven best practices for
salmon data stewardship and demonstrate their application through a
real-world case study of cross-jurisdictional sockeye productivity
analysis. Our case study shows how cross-jurisdictional alignment of
terms and reproducible pipelines can enable faster status assessment
updates and more responsive management decisions. Our goal is to support
salmon biologists and the broader research and management community to
effectively steward salmon data. To keep this broadly useful, we
emphasize patterns---lifecycle planning, metadata governance, vocabulary
alignment, reproducible publishing, and role clarity---that any
taxa-centric community can adopt, substituting their own standards and
tools. We also map the seven practices to widely used data-lifecycle
models to make adoption straightforward outside salmon contexts.

A coordinated approach to stewarding salmon data should follow
established open science standards and adhere explicitly to FAIR
principles, tailored specifically for salmon research and management.
Our practices build upon existing standards and vocabularies including
Darwin Core, OBIS, schema.org, and OBO Foundry ontologies, ensuring
compatibility with broader biodiversity informatics infrastructure
rather than reinventing foundational frameworks. Achieving meaningful
interoperability demands both breadth and depth. \textbf{Broad
interoperability} integrates diverse scientific domains, systems, and
formats, requiring structured, machine-readable data and metadata
published openly for maximum discoverability. \textbf{Deep
interoperability} demands precise definitions of salmon-specific terms
and methods, ensuring data remains meaningful and usable across
contexts. Salmon data stewards can improve conservation outcomes for
salmon by coordinating across boundaries to develop a shared foundation
of data stewardship practices. To address these foundational challenges,
we must establish clear data stewardship roles and practices that span
the entire data lifecycle---from collection and documentation through
integration and long-term preservation.

\subsection{Defining Data Stewardship in Salmon
Science}\label{defining-data-stewardship-in-salmon-science}

Data stewardship encompasses the coordinated practices, roles, and
responsibilities necessary to effectively manage, share, and reuse data
throughout its lifecycle (NOAA 2007; Plotkin 2014; Peng et al. 2018).
Within fisheries science, stewardship involves ensuring data quality,
compliance with agreed-upon standards, and the establishment of clear
governance to guide data collection, documentation, integration, and
preservation. However, salmon data stewardship goes beyond mere
technical data management; it involves actively facilitating
collaboration, communication, and consensus-building among data
producers and users across multiple institutions and jurisdictions.

Data stewardship represents a critical subdiscipline within the broader
field of data science. While data science is often narrowly associated
with machine learning and statistical modeling, we adopt a more
comprehensive view that encompasses how we treat, handle, and represent
data, along with the social and technical information systems that
enable data use for science. Data stewardship focuses on the practical
implementation of these principles---ensuring that data infrastructure,
standards, and practices actually serve scientific and management needs
rather than remaining theoretical constructs.

Effective salmon data stewards serve as boundary spanners and community
managers, convening diverse stakeholders across agencies, First Nations,
Tribes, and academic institutions to build sustained communities of
practice. This boundary-spanning role is particularly critical in
transboundary contexts where data integration requires navigating
complex jurisdictional and cultural boundaries (Ward et al. 2025). By
facilitating communication, translating between different organizational
cultures and technical systems, and maintaining long-term relationships,
data stewards create the social infrastructure necessary for effective
cross-boundary data collaboration.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, left=2mm, arc=.35mm, bottomrule=.15mm, colback=white, coltitle=black, colbacktitle=quarto-callout-note-color!10!white, breakable, bottomtitle=1mm, toptitle=1mm, leftrule=.75mm, rightrule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Box 1: Critical Functions of Salmon Data Stewards}, colframe=quarto-callout-note-color-frame, toprule=.15mm, titlerule=0mm, opacitybacktitle=0.6]

Effective salmon data stewards perform several critical functions:

\begin{itemize}
\item
  \textbf{Technical oversight}: Ensuring metadata completeness,
  adherence to standardized terminologies and vocabularies, and robust
  quality assurance protocols.
\item
  \textbf{Social and organizational facilitation}: Leading stakeholder
  engagement, capacity-building activities, and negotiation of data
  access and sharing agreements, including addressing First Nations,
  Tribes, and Indigenous Peoples' rights and interests in data
  governance.
\item
  \textbf{Institutional advocacy}: Championing the institutional
  recognition of data stewardship roles, promoting sustained investment
  and dedicated resources for data management infrastructure and
  practices.
\item
  \textbf{Implementation and adoption facilitation}: Actively promoting
  data use and ensuring that standards and practices remain practical
  and relevant by maintaining close contact with real-world
  applications. This includes monitoring data utilization, gathering
  feedback from users, and iteratively refining standards based on
  actual implementation challenges to prevent theoretical approaches
  that fail in practice.
\end{itemize}

\end{tcolorbox}

Data stewards can implement FAIR and CARE principles through concrete
technical and governance mechanisms they control, such as documenting
consent constraints and access levels in metadata, using controlled
vocabularies to ensure consistent terminology, and establishing
repository roles that enforce data sovereignty requirements. For
example, stewards can document consent constraints in metadata fields
and enforce access restrictions via repository user roles, ensuring that
Indigenous data sovereignty is respected while maintaining data
discoverability and appropriate reuse. This governance approach is
particularly critical for sensitive data such as Traditional Knowledge
and sensitive habitat locations, where stewardship practices must
balance open science principles with appropriate access controls and
cultural protocols.

Data stewards play a critical role bridging the gap between biologists
and Information Technology (IT) staff by translating data needs into
application or data system features. A user-centred design approach to
salmon data stewardship is critical and focuses on creating tools that
align with biologists' needs. When data management is separated from
biologists, accountability weakens, and quality issues go unnoticed.
While IT expertise is essential for infrastructure and security,
effective data system design requires IT to act as an enabler, rather
than gatekeeper, provisioning self-serve data infrastructure. The Data
Steward, serving as a translator between IT and biologists, enables
biologists to engage independently with data systems, fostering
ownership and accountability and ultimately improving data quality for
research and management.

Dedicated stewardship roles empower salmon biologists to bridge
disciplinary divides and jurisdictional barriers, transforming
fragmented datasets into cohesive, interoperable resources. By
proactively defining, implementing, and maintaining data standards and
workflows, salmon data stewards create conditions for timely, accurate,
and reproducible analyses. Such stewardship positions salmon biologists
to better inform adaptive management decisions, ultimately strengthening
salmon conservation and resilience.

\subsection{Updating Pacific-wide Sockeye Productivity: A Case Study for
What Agencies Could Do
Now}\label{updating-pacific-wide-sockeye-productivity-a-case-study-for-what-agencies-could-do-now}

This case study revisits a Pacific Coast-wide sockeye productivity
dataset assembled from diverse agency sources by academic researchers
(Peterman and Dorner 2012). We reflect not on the significant work the
research team accomplished, but rather on the preventable institutional
and technical barriers that impeded their work---and continue to burden
data updates and reuse efforts today. Their study examined productivity
trends across 64 sockeye salmon stocks spanning Washington, British
Columbia (B.C.), and Alaska. However, attempting to replicate or build
upon this analysis today is an arduous, time-consuming, and error-prone
endeavour due to fragmented data sources, inconsistent formats, and lack
of standardized practices among the key institutions involved: the
Washington Department of Fish and Wildlife (WDFW), Fisheries and Oceans
Canada (DFO), and the Alaska Department of Fish and Game (ADF\&G).

Each section below highlights a key challenge faced by the team and
proposes practical steps based on our best practices
(Table~\ref{tbl-bestpractices}) that data-holding agencies could do to
enable easier integration, validation, and updating of salmon datasets
across jurisdictions and decades. This case study illustrates how
implementing the foundational concepts and practical recommendations
outlined in this paper can transform data stewardship practices within
these organizations. By doing so, they can significantly enhance data
accessibility, quality, and interoperability---ultimately enabling more
efficient and accurate analyses that support salmon conservation and
management.

\subsubsection{Challenge 1: Interpreting the Data --- What do these
numbers actually
mean?}\label{challenge-1-interpreting-the-data-what-do-these-numbers-actually-mean}

Peterman's team frequently worked with datasets that lacked basic
contextual information. Fields such as ``year,'' ``return,'' or ``age
class'' were often undefined or inconsistently used. For example, some
datasets recorded returns by calendar year while others used brood year,
and few included metadata to clarify the distinction. In many cases, the
team had to reconstruct metadata by back-checking against reports or
simulating assumptions (e.g., about age structure) to interpret the data
correctly.

\textbf{Remedies:}

\begin{itemize}
\item
  \textbf{Best Practice 3: Make Data, People, Projects, and Outputs
  Discoverable, Linked and Citable with Persistent Identifiers (PIDs).}
  Assigning PIDs such as digital object identifiers (DOIs) to protocols,
  methods, and people (via ORCIDs) and linking them together using data
  stores and catalogues links data to its provenance and ensures that
  methods, context, and interpretation decisions are traceable.
\item
  \textbf{Best Practice 4. Use Shared Data Models, Vocabularies and
  Metadata to Enable Integration.} To prevent this kind of ambiguity,
  agencies can now adopt internationally recognized metadata schemas
  such as ISO 19115 or Ecological Metadata Language, data models (Darwin
  Core Data Package) to model age and age type data concepts, and use
  controlled vocabularies to restrict the permissible values in the age
  field to calendar year, brood year, or otherwise.
\end{itemize}

\subsubsection{Challenge 2: Accessing and Using the Data --- Where is it
stored, and how do I get
it?}\label{challenge-2-accessing-and-using-the-data-where-is-it-stored-and-how-do-i-get-it}

The Peterman dataset was compiled from multiple files scattered across
email inboxes, regional offices, and grey literature. Data were stored
in inconsistent formats, lacked clear versioning, and were difficult to
discover outside of specific research networks. Even today, no API or
structured access mechanism exists to update or query the data
programmatically. As a result, researchers hoping to build on the
dataset may have to start from scratch.

\textbf{Remedies:}

\begin{itemize}
\item
  \textbf{Best Practice 2: Reuse Proven Infrastructure to Save Time and
  Increase Interoperability}\\
  Rather than developing bespoke data catalogues or repositories,
  agencies should adopt existing catalogues used beyond their own
  institution such as the Ocean Biodiversity Information System, Zenodo,
  or the Knowledge Network for Biocomplexity). These are proven
  platforms with a broad user base that support persistent storage,
  discoverability, and interoperability.
\item
  \textbf{Best Practice 5: Store and Analyze Data in Ways That Others
  Can Easily Access, Use, and Trust}\\
  Agencies can use open-access data repositories or their own
  institutional data repositories or catalogues that make data
  discoverable using PIDs and provide programmatic access to data
  possible using Application Programming Interfaces.
\end{itemize}

\subsubsection{Challenge 3: Sustaining the Dataset --- Who is
responsible, and why should I
contribute?}\label{challenge-3-sustaining-the-dataset-who-is-responsible-and-why-should-i-contribute}

Once Peterman and his team completed their analysis, no formal plan
existed for sustaining or updating the dataset. Responsibility for
ongoing maintenance fell informally to former students and
collaborators. Despite its national and international relevance, the
dataset was never adopted by an agency as a living product. Moreover,
the original data contributors often lacked incentives, support, or
recognition for their efforts---conditions that persist in many data
environments today.

\textbf{Remedies:}

\begin{itemize}
\item
  \textbf{Best Practice 1: Make Data Governance Explicit to Support
  Trust and Reuse} Agencies should define roles, responsibilities, and
  decision-making processes through formal governance mechanisms such as
  data product charters. Use a Data Management Plan with a
  responisibility matrix such as ``responsible, approver, consulted,
  informed'' (RACI) to clarify govermamce, assign maintenance
  responsibility, and ensure continuity across staff turnover and
  institutional change.
\item
  \textbf{Best Practice 6: Incentivize and Track Data Sharing and Reuse}
  Visibility, credit, and metrics are critical for motivating data
  sharing. Agencies can embed citation guidance in metadata and track
  dataset reuse through COUNTER-compliant dashboards or DataCite APIs.
\item
  \textbf{Best Practice 7: Build Community Through Co-Development and
  Mutual Benefit} Effective data stewardship requires collaboration
  between biologists, First Nations, Tribes, Indigenous communities,
  managers, and data professionals. Participatory design ensures that
  systems and standards meet user needs and are adopted over time.
  \emph{Practical application:} Facilitate cross-jurisdictional working
  groups to co-develop data standards and align on shared outcomes for
  priority datasets.
\end{itemize}

While the analytical contribution of the Peterman productivity dataset
remains significant, the barriers encountered in compiling,
interpreting, and maintaining the data are instructive. These challenges
are not unique to Peterman's team---they reflect systemic gaps in data
governance, documentation, infrastructure, and incentives. By adopting
the seven best practices detailed in Table~\ref{tbl-bestpractices},
agencies and researchers can transform legacy datasets into living
resources, enabling reproducibility, easing collaboration, and
accelerating insight across the salmon research and management
community.

The challenges and solutions demonstrated in this salmon case study
generalize across fisheries and environmental monitoring domains.
Cross-jurisdictional data harmonization, quality assurance and control
patterns, standardized metadata requirements, and long-term archiving
strategies are universal needs that extend far beyond salmon science.
Similar barriers and solutions apply to trawl survey data integration,
invertebrate monitoring programs, and water quality datasets that span
multiple agencies and jurisdictions.

\subsubsection{How our seven practices align to data lifecycle
models}\label{how-our-seven-practices-align-to-data-lifecycle-models}

Our seven best practices map directly to established data lifecycle
models, demonstrating their broad applicability beyond salmon science.
The NOAA Data Lifecycle provides a widely recognized framework with six
sequential stages (Plan, Obtain, Process, Preserve, Access, Disposition)
and four cross-cutting elements (Document, Track and Monitor, Quality,
Security) (NOAA Data Governance Committee 2024). This alignment ensures
our practices are grounded in established federal data management
standards and can be readily adopted by other agencies and research
communities.

The mapping shown in Table~\ref{tbl-lifecycle} demonstrates how each
practice addresses specific lifecycle stages while the cross-cutting
elements ensure comprehensive data stewardship throughout the entire
lifecycle. For example, Practice 1 (Data Governance) spans the entire
lifecycle from planning through disposition, while Practice 4 (Shared
Data Models) primarily supports the Process and Preserve stages. This
systematic alignment with established frameworks enhances the
credibility and portability of our approach across different domains and
institutions.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.2689}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0672}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0756}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0840}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0924}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0756}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1681}}@{}}
\caption{Mapping of seven best practices to NOAA Data Lifecycle stages
and cross-cutting elements}\label{tbl-lifecycle}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Best Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Plan
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Obtain
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Process
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Preserve
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Access
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Disposition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cross-cutting
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Best Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Plan
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Obtain
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Process
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Preserve
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Access
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Disposition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cross-cutting
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{1. Data Governance} & ● & ● & ● & ● & ● & ● & Document,
Quality \\
\textbf{2. Reuse Infrastructure} & ● & & & ● & ● & & Track and
Monitor \\
\textbf{3. Persistent Identifiers} & ● & & & ● & ● & ● & Document,
Track \\
\textbf{4. Shared Data Models} & ● & & ● & ● & & & Quality \\
\textbf{5. Accessible Storage} & & & ● & ● & ● & & Security, Quality \\
\textbf{6. Incentivize Sharing} & ● & & & ● & ● & & Track and Monitor \\
\textbf{7. Community Building} & ● & ● & ● & ● & ● & ● & Document,
Quality \\
\end{longtable}

\subsubsection{Metadata governance as a cross-cutting
foundation}\label{metadata-governance-as-a-cross-cutting-foundation}

Unlike the sequential stages of the data lifecycle, metadata governance
operates as a continuous, cross-cutting practice that spans all phases
simultaneously. While data moves through Plan → Obtain → Process →
Preserve → Access → Disposition, metadata governance must be active
throughout, ensuring that documentation, quality control, and
discoverability are maintained at every stage. This cross-cutting nature
means that metadata governance failures at any point can compromise the
entire data stewardship effort, making it a critical foundation rather
than a discrete step in the process.

The lifecycle mapping in Table~\ref{tbl-lifecycle} reveals that data
governance elements appear in every stage: planning metadata
requirements (Plan), documenting collection methods (Obtain),
structuring and validating metadata (Process), ensuring long-term
preservation (Preserve), enabling discovery and access (Access), and
managing final disposition (Disposition). This pervasive presence
underscores why metadata governance must be treated as an institutional
capability rather than a project-specific task, requiring dedicated
resources, trained personnel, and systematic processes that operate
continuously across all data activities.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7035}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2965}}@{}}
\caption{Best practices and practical applications of salmon data
stewardship}\label{tbl-bestpractices}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Best Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Practical Applications
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Best Practice
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Practical Applications
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{1. Make Data Governance Explicit to Support Trust and Reuse.}
Establishing clear governance structures ensures quality,
accountability, and compliance with FAIR and CARE principles. It enables
trust and long-term stewardship across multi-organizational projects. &
- Document roles and responsibilities using a Data Product Governance
Charter and structured frameworks (e.g., DACI or RACI).

- Integrate CARE principles to respect First Nations, Tribes, and
Indigenous data rights.

- Form a governance or oversight committee to review data standards,
timelines, and agreements. \\
\textbf{2. Reuse Proven Infrastructure to Save Time and Increase
Interoperability.} Leveraging existing platforms and technologies
reduces costs and improves long-term interoperability and
sustainability. & - Use domain-specific repositories like OBIS or GBIF.

- Publish and archive data with KNB or Zenodo. \\
\textbf{3. Make Data, People, Projects, and Outputs Discoverable, Linked
and Citable with PIDs.} Persistent identifiers (PIDs) connect data with
researchers, institutions, and outputs---supporting data citation,
reuse, and automated attribution. & - Encourage use of ORCID iDs for
researchers.

- Use ROR IDs for institutions.

- Assign DOIs via DataCite for data packages.

- Embed DOIs in dashboards and metadata. \\
\textbf{4. Use Shared Data Models, Ontologies and Metadata to Enable
Integration.} Common vocabularies, metadata standards, and ontologies
support integration across systems and preserve semantic meaning. & -
Adopt ISO 19115, EML, or DataCite metadata standards.

- Re-use terms defined in Salmon Domain Ontology.

- Model datasets using the Darwin Core Data Package Model. \\
\textbf{5. Store and Analyze Data in Ways That Others Can Easily Access,
Use and Trust.} Structured and accessible data formats ease reusability,
and support integration with analytical tools and applications while
data analyzed or wrangled using programmatic scripts (R, Python etc.)
enable reproducibility and increase trust. & - Provide APIs using
FastAPI, Flask, or Django REST.

- Archive in trusted repositories (e.g., GBIF, FRDR, USGS).

- Write scripts in a programming language to wrangle, transform, and
analyze data.

- Use GitHub to host code for collaboration and transparency and the
GitHub / Zenodo integration for DOI assignment and preservation. \\
\textbf{6. Incentivize and Track Data Sharing and Reuse.} Recognizing
data contributors and tracking reuse promotes a culture of sharing and
supports professional recognition. & - License data with CC-BY 4.0.

- Include citation text and visible credit fields.

- Use COUNTER metrics and DataCite APIs to monitor reuse.

- Encourage dataset citation in references. \\
\textbf{7. Build Community Through Co-Development and Mutual Benefit.}
Engaging users early ensures tools and standards meet real-world needs
and enhances long-term stewardship. & - Participate in RDA Salmon
Interest Group.

- Facilitate workshops for metadata and vocabulary alignment.

- Support community-engaged research with tangible benefits. \\
\end{longtable}

\subsection{Conclusion}\label{conclusion}

Salmon biologists and data stewards across the globe have generated
extensive datasets on salmon abundance, environmental conditions, and
biological characteristics. When integrated, these data become valuable
assets, a fact powerfully demonstrated by studies such as (Peterman and
Dorner 2012). However, as noted by reports to the Cohen Commission
(Marmorek et al. 2011), these data are often incomplete, inconsistently
collected, and fragmented across institutions and jurisdictions.
Integrating across such diverse sources can be done, but requires effort
that is often not accounted for in smaller-scale studies. This
fragmentation is a missed opportunity to deepen our understanding of the
drivers of change across salmon life stages and regions, and limits the
effectiveness of management decisions, particularly in the face of
climate change and biodiversity loss.

But this limitation also reveals an opportunity. By adopting shared best
practices in data governance, metadata standardization, persistent
identification, infrastructure reuse, and community co-development we
can radically improve the transparency, reusability, and
interoperability of salmon data. A coordinated, future-oriented data
stewardship strategy can transform the role of salmon data in science
and management. The case study presented in this paper---drawn from one
of the Pacific Region's most influential salmon survival syntheses
(Peterman and Dorner 2012)---illustrates how technical and social data
management gaps directly obstructed efforts to answer pressing
questions. If some of the best practices we propose had been adopted by
the data producers---such as documenting their datasets more thoroughly,
storing data in accessible formats, or using persistent
identifiers---substantial time and resources could have been saved. The
case offers a clear and cautionary tale, as well as a hopeful roadmap.

The emergence of the data stewardship role (Plotkin 2014) represents one
of the most critical institutional shifts needed to realize this vision.
Historically, the work of managing, documenting, and maintaining data
has been diffuse and undervalued---often falling to biologists without
support, training, or recognition. As the volume and complexity of
scientific data grow, so too does the need for clearly defined data
stewardship responsibilities embedded within research teams and
organizations. Training biologists in the principles and practices of
data stewardship---while also supporting dedicated professionals who
specialize in this work---is essential to sustaining trustworthy,
reusable, and interoperable salmon data systems.

Realizing this vision requires concrete institutional commitments
organizations should formally appoint dedicated data stewards with clear
roles, responsibilities, and reporting structures. Agencies can adopt
centralized metadata repositories and establish compliance metrics to
track progress toward FAIR and CARE principles. Key implementation steps
include: (1) designating stewardship roles within existing
organizational structures, (2) investing in metadata management
infrastructure, (3) establishing data governance committees with
cross-organization representation, and (4) developing performance
indicators that measure data discoverability, interoperability, and
reuse. These institutional changes ensure that data stewardship becomes
embedded in organizational culture rather than remaining an ad hoc
responsibility.

The visionary future state is one where salmon researchers and
stewards---across agencies, Indigenous Nations, academic labs, and
community groups---can easily access and contribute to well-documented,
versioned, and machine-readable datasets. In this future, field
biologists, Indigenous guardians, modelers, and policymakers interact
with a living knowledge system---one that is flexible, easy to
implement, and rooted in principles of FAIRness Indigenous Data
Sovereignty. Metadata standards, controlled vocabularies, and shared
governance frameworks are not afterthoughts but integral to the culture
of data collection and use. Scientists receive credit for publishing
high-quality data, and users trust the provenance and structure of the
datasets they rely on to make critical management decisions.

Realizing this vision will require investment in both people and
systems. Key to this transformation is the emergence of the data steward
as a professional role: a hybrid expert who understands operational
field biology, information science, governance protocols, and community
needs. As highlighted by Roche et al. (2020), institutionalizing data
stewardship roles ensures long-term capacity for data governance,
quality control, and interoperability---functions that are often
neglected or left to informal actors. We must not only train new data
stewards but also support and upskill biologists to take on stewardship
responsibilities in collaborative, interdisciplinary settings. This is
essential to address the ``technical debt'' of unmanaged data and to
modernize research practices in line with open science norms. By
embedding these practices into the everyday work of data generation,
documentation, publication, and reuse, we can move salmon science
decisively into the era of data-intensive discovery.

To do items:

\begin{itemize}
\tightlist
\item
  Discuss differences between data management plans, data governance
  charters, data sharing agreements
\item
  Incorporate ref to Streamnet Data Exchange Standards somehow
\item
  Add in figures
\item
  fill out appendix 1 more thoroughly
\item
  Refine Reorg the content in appendix 2 (traning roadmap) and decide if
  it Makes sense to put some of that content into a 3rd column in table
  1
\end{itemize}

\subsubsection{Competing interests}\label{competing-interests}

\subsubsection{Acknowledgements}\label{acknowledgements}

\subsubsection{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-bull2022}
Bull, C D, S D Gregory, E Rivot, T F Sheehan, D Ensing, G Woodward, and
W Crozier. 2022. {``The Likely Suspects Framework: The Need for a Life
Cycle Approach for Managing Atlantic Salmon ({\emph{Salmo Salar}})
Stocks Across Multiple Scales.''} Edited by Wesley Flannery. \emph{ICES
Journal of Marine Science} 79 (5): 1445--56.
\url{https://doi.org/10.1093/icesjms/fsac099}.

\bibitem[\citeproctext]{ref-carroll2019}
Carroll, Stephanie Russo, Desi Rodriguez-Lonebear, and Andrew Martinez.
2019. {``Indigenous Data Governance: Strategies from United States
Native Nations.''} \emph{Data Science Journal} 18 (1): 31.
\url{https://doi.org/10.5334/dsj-2019-031}.

\bibitem[\citeproctext]{ref-diack2024}
Diack, Graeme, Tom Bird, Scott Akenhead, Jennifer Bayer, Deirdre Brophy,
Colin Bull, Elvira de Eyto, et al. 2024. {``Salmon Data Mobilization.''}
\emph{North Pacific Anadromous Fish Commission Bulletin}, December.
\url{https://doi.org/10.23849/npafcb7/x3rlpo23a}.

\bibitem[\citeproctext]{ref-eartheconomics2021}
Earth Economics. 2021. {``The Sociocultural Significance of Pacific
Salmon to Tribes and First Nations.''} Tacoma, Washington.
\url{https://www.psc.org/wp-content/uploads/wpfd/preview_files/The-Sociocultural-Significance-of-Salmon-to-Tribes-and-First-Nations(5da9942da9fb4fe0d77eb32bd6165e43).pdf}.

\bibitem[\citeproctext]{ref-groot1991}
Groot, Cornelis, and L. Margolis. 1991. \emph{Pacific Salmon Life
Histories}. UBC Press.
\url{https://books.google.ca/books?id=I_S0xCME0CYC}.

\bibitem[\citeproctext]{ref-inman2021}
Inman, Sarah, Janessa Esquible, Michael Jones, William Bechtol, and
Brendan Connors. 2021. {``Opportunities and Impediments for Use of Local
Data in the Management of Salmon Fisheries.''} \emph{Ecology and
Society} 26 (2). \url{https://doi.org/10.5751/ES-12117-260226}.

\bibitem[\citeproctext]{ref-jennings2023a}
Jennings, Lydia, Talia Anderson, Andrew Martinez, Rogena Sterling,
Dominique David Chavez, Ibrahim Garba, Maui Hudson, Nanibaa' A.
Garrison, and Stephanie Russo Carroll. 2023. {``Applying the {`}CARE
Principles for Indigenous Data Governance{'} to Ecology and Biodiversity
Research.''} \emph{Nature Ecology \& Evolution} 7 (10): 1547--51.
\url{https://doi.org/10.1038/s41559-023-02161-2}.

\bibitem[\citeproctext]{ref-johnson2024}
Johnson, Brett, and Tim van der Stap. 2024. {``Data Mobilization Through
the International Year of the Salmon Ocean Observing System.''}
\emph{North Pacific Anadromous Fish Commission Bulletin}, December.
\url{https://doi.org/10.23849/npafcb7/6a4ddpde4}.

\bibitem[\citeproctext]{ref-lindenmayer2012}
LINDENMAYER, DAVID B., GENE E. LIKENS, ALAN ANDERSEN, DAVID BOWMAN, C.
MICHAEL BULL, EMMA BURNS, CHRIS R. DICKMAN, et al. 2012. {``Value of
Long{-}Term Ecological Studies.''} \emph{Austral Ecology} 37 (7):
745--57. \url{https://doi.org/10.1111/j.1442-9993.2011.02351.x}.

\bibitem[\citeproctext]{ref-marmorek2011}
Marmorek, David, Darcy Pickard, Alexander Hall, Katherine Bryan, Liz
Martell, Clint Alexander, Katherine Wieckowski, Lorne Greig, and Carl
Schwarz. 2011. {``Cohen Commision Technical Report 6-Fraser River
Sockeye Salmon: Data Synthesis and Cumulative Impacts.''} Vancouver,
B.C. \url{http://www.cohencommission.ca/}.

\bibitem[\citeproctext]{ref-environm2007}
NOAA. 2007. \emph{Environmental Data Management at NOAA}. National
Academies Press. \url{https://doi.org/10.17226/12017}.

\bibitem[\citeproctext]{ref-noaadatagovernancecommittee2024}
NOAA Data Governance Committee. 2024. {``Management of NOAA Data and
Information, Data Management Handbook,''} January.
\url{https://www.noaa.gov/sites/default/files/2025-03/NAO_212-15B_-_Data_Management_Handbook.pdf}.

\bibitem[\citeproctext]{ref-peng2018}
Peng, Ge, Jeffrey L. Privette, Curt Tilmes, Sky Bristol, Tom Maycock,
John J. Bates, Scott Hausman, Otis Brown, and Edward J. Kearns. 2018.
{``A Conceptual Enterprise Framework for Managing Scientific Data
Stewardship.''} \emph{Data Science Journal} 17.
\url{https://doi.org/10.5334/dsj-2018-015}.

\bibitem[\citeproctext]{ref-peterman2012}
Peterman, Randall~M., and Brigitte Dorner. 2012. {``A Widespread
Decrease in Productivity of Sockeye Salmon ({\emph{Oncorhynchus Nerka}})
Populations in Western North America.''} Edited by Jordan S. Rosenfeld.
\emph{Canadian Journal of Fisheries and Aquatic Sciences} 69 (8):
1255--60. \url{https://doi.org/10.1139/f2012-063}.

\bibitem[\citeproctext]{ref-plotkin2014}
Plotkin, David. 2014. \emph{Data Stewardship}. Elsevier.
\url{https://doi.org/10.1016/c2012-0-07057-3}.

\bibitem[\citeproctext]{ref-roche2020}
Roche, Dominique G., Monica Granados, Claire C. Austin, Scott Wilson,
Gregory M. Mitchell, Paul A. Smith, Steven J. Cooke, and Joseph R.
Bennett. 2020. {``Open Government Data and Environmental Science: A
Federal Canadian Perspective.''} Edited by Tanzy Love. \emph{FACETS} 5
(1): 942--62. \url{https://doi.org/10.1139/facets-2020-0008}.

\bibitem[\citeproctext]{ref-volk2014}
Volk, Carol J., Yasmin Lucero, and Katie Barnas. 2014. {``Why Is Data
Sharing in Collaborative Natural Resource Efforts so Hard and What Can
We Do to Improve It?''} \emph{Environmental Management} 53 (5): 883--93.
\url{https://doi.org/10.1007/s00267-014-0258-2}.

\bibitem[\citeproctext]{ref-ward_surveyjoin_2025}
Ward, Eric J, Philina A English, Christopher N Rooper, Bridget E
Ferriss, Curt E Whitmire, Chantel R Wetzel, Lewis Ak Barnett, et al.
2025. {```Surveyjoin`: {A} {Standardized} {Database} of {Fisheries}
{Bottom} {Trawl} {Surveys} in the {Northeast} {Pacific} {Ocean}.''}
\url{https://doi.org/10.1101/2025.03.14.643022}.

\bibitem[\citeproctext]{ref-ween2013}
Ween, Gro, and Benedict Colombi. 2013. {``Two Rivers: The Politics of
Wild Salmon, Indigenous Rights and Natural Resource Management.''}
\emph{Sustainability} 5 (2): 478--95.
\url{https://doi.org/10.3390/su5020478}.

\bibitem[\citeproctext]{ref-wilkinson2016}
Wilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg,
Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al.
2016. {``The FAIR Guiding Principles for Scientific Data Management and
Stewardship.''} \emph{Scientific Data} 3 (1): 160018.
\url{https://doi.org/10.1038/sdata.2016.18}.

\end{CSLReferences}

\section{Appendices}\label{appendices}

\section{}\label{section}

\subsection{Appendix 1. Real-world Example Applications of the Best
Practices}\label{appendix-1.-real-world-example-applications-of-the-best-practices}

Here we provide detailed descriptions of the seven best practices for
salmon data stewardship, along with practical applications and
real-world examples. This is not an exhaustive list, but rather a
starting point for salmon biologists and data stewards to implement
effective data stewardship practices in their work based on examples
from the salmon research and management community.

\paragraph{\texorpdfstring{\textbf{1. Make Data Governance Explicit to
Support Trust and
Reuse}}{1. Make Data Governance Explicit to Support Trust and Reuse}}\label{make-data-governance-explicit-to-support-trust-and-reuse}

Clear governance defines roles, responsibilities, and procedures
ensuring data quality, long-term maintenance, accountability, and
compliance with community principles such as FAIR and CARE. Effective
governance fosters trust, facilitates data sharing, reduces ambiguity
regarding decision making, and is critical for coordinating both
technical and sociocultural aspects of data stewardship.

In collaborative international or multi-organizational settings,
establishing governance at the outset of a project is crucial for
aligning diverse groups, including biologists, data managers, Indigenous
communities, policymakers, and other participants. Early governance
planning should establish clear, collaborative frameworks that respect
each group's expertise and needs from the beginning.~

\subparagraph{Practical Applications:}\label{practical-applications}

1.1 Document roles and responsibilities clearly at project start using a
Project or Data Product Governance Charter and structured frameworks
(e.g., DACI or RACI charts) that relate to organizational data policies.

\begin{itemize}
\item
  \href{https://raw.githubusercontent.com/Br-Johnson/sdm-paper/refs/heads/main/examples/Cal_DMP.pdf}{Example
  of a Data Management Plan from the California Department of Water
  Resources}
\item
  Data Management Plan Templates from
  \href{https://dmptool.org/public_templates?page=ALL}{DMPTool}, and
  \href{https://www.noaa.gov/sites/default/files/2025-03/NAO_212-15B_-_Data_Management_Handbook.pdf}{NOAA
  Data Management Handbook}
\end{itemize}

1.2 Integrate CARE principles to ensure ethical governance and respect
Indigenous data rights.

\begin{itemize}
\tightlist
\item
  Northwest Indian Fisheries Commission use password protected website
  to host all the WDFW and tribal data in a one-stop shopping website
  for co-managers to pull data they need for decision-making process.
  \url{https://fisheriesservices.nwifc.org/}
\end{itemize}

1.3 Create a governance or oversight committee for regular data practice
reviews and decision making regarding data structures, timelines, data
sharing agreements and interoperability protocols

\begin{itemize}
\tightlist
\item
  Pacific Salmon Commission has formed a Technical Committee on Data
  Sharing including both US and Canadian data contributors.
  \url{https://www.psc.org/membership-lists/}
\end{itemize}

\paragraph{\texorpdfstring{\textbf{2. Reuse Proven Infrastructure to
Save Time and Increase
Interoperability}}{2. Reuse Proven Infrastructure to Save Time and Increase Interoperability}}\label{reuse-proven-infrastructure-to-save-time-and-increase-interoperability}

Building custom solutions should be avoided where possible. Maximizing
existing platforms and technologies reduces costs, accelerates
implementation, and increases data interoperability. Building modular,
interoperable systems grounded in proven technologies ensures
sustainable long-term stewardship.

\subparagraph{Practical Applications:}\label{practical-applications-1}

2.1 \href{https://doi.org/10.14286/duc6mu}{Use the Ocean Biodiversity
Information System or the Global Biodiversity Information Facility to
standardize and host your data}

2.2 Use free data catalogue services such as the Knowledge Network for
Biocomplexity (KNB) or Zenodo

\begin{itemize}
\tightlist
\item
  The Pacific Salmon Foundation's
  \href{https://doi.org/10.5281/zenodo.14194638}{spawner surveys dataset
  on Zenodo} (Carturan and Peacock 2025) received more views within
  weeks than a
  \href{https://data.salmonwatersheds.ca/result?datasetid=2}{analogous
  dataset in the Salmon Data Library} (Pacific Salmon Foundation 2025)
  did over several years, illustrating that leveraging established
  public data infrastructures, rather than developing
  institution-specific ones, can substantially increase discoverability.
\end{itemize}

\paragraph{\texorpdfstring{\textbf{3. Make Data, People, Projects, and
Outputs Discoverable, Linked and Citable with
PIDs}}{3. Make Data, People, Projects, and Outputs Discoverable, Linked and Citable with PIDs}}\label{make-data-people-projects-and-outputs-discoverable-linked-and-citable-with-pids}

Persistent identifiers (PIDs), including Digital Object Identifiers
(DOI) are essential for tracking the provenance and reuse of data, and
linking data, protocols, organizations and people. They allow for
consistent referencing, integration across systems, and automated credit
via data citation.

\subparagraph{Practical Applications:}\label{practical-applications-2}

3.1 Encourage researchers to register for an
\href{https://orcid.org/}{Open Researcher and Contributor ID (ORCID)}
and include ORCIDs in metadata records and submission forms

3.2 Register your organization with the Research Organization Registry
(ROR) and use ROR IDs to identify institutions involved in salmon
science.

\begin{itemize}
\tightlist
\item
  Several salmon data holding institutions are already
  \href{https://ror.org/search?page=1&query=salmon}{registered with
  ROR}. As a result, those organizations can track and demonstrate their
  scholarly impact from data publications:
  \href{https://commons.datacite.org/ror.org/04901nj56}{DataCite
  Commons: Pacific Salmon Foundation}
\end{itemize}

3.3 Assign DOIs to data packages, protocols, and reports using DataCite.
Maintain version history for all metadata records and document the
provenance of metadata creation, updates, and quality control processes
to ensure accountability and traceability.

\begin{itemize}
\tightlist
\item
  The North Pacific Anadromous FIsh Commission (NPAFC) assigns DOIs to
  IYS-related data packages which are served by a CKAN catalogue at
  \url{https://data.npafc.org}. The Commission also assigns DOIs to
  NPAFC Technical Reports and Bulletins.
\end{itemize}

3.4 Embed DOIs in dashboards, figures, and metadata so they persist in
derivative products.

\paragraph{\texorpdfstring{\textbf{4. Use Shared Data Models,
Vocabularies and Metadata to Enable
Integration}}{4. Use Shared Data Models, Vocabularies and Metadata to Enable Integration}}\label{use-shared-data-models-vocabularies-and-metadata-to-enable-integration}

Standardizing metadata and terminology ensures data can be interpreted
correctly and integrated across systems. Controlled vocabularies,
community ontologies, and structured metadata schemas allow data to
retain its full semantic meaning.

\subparagraph{Practical Applications:}\label{practical-applications-3}

4.1 Configure data catalogues and metadata intake tools to accept
internationally recognized metadata schemas such as ISO 19115,
Ecological Metadata Language (EML), or DataCite. Implement automated
validation against schema requirements and manual review processes to
ensure metadata completeness, accuracy, and consistency before
publication.

\begin{itemize}
\tightlist
\item
  The Pacific Salmon Foundation's data portal asks contributors to
  provide metadata in ISO 19115 or other standard formats.
  marinedata.psf.ca, ensuring consistent metadata structure
\item
  The NPAFC uses ISO 19115 metadata standard in their data catalogue
  https://data.npafc.org
\end{itemize}

4.2 Model datasets and databases using the
\href{https://dwc.tdwg.org/}{Darwin Core Standard}

\begin{itemize}
\item
  The Hakai Institute Juvenile Salmon Program publishes their data to
  OBIS using Darwin Core:
  \href{https://www.gbif.org/dataset/72de3af4-1572-4f2d-8006-2bfa2007065c}{Hakai
  Institute Juvenile Salmon Program}
\item
  The International Year of the Salmon High Seas Expeditions data
  mobilization efforts {[}Johnson and Stap (2024){]} published their
  data to OBIS: \url{https://www.gbif.org/dataset/search?project_id=IYS}
\end{itemize}

4.3 Re-use or publish data terms that are shared online using a
persistent identifier in a controlled vocabulary or ontology

\begin{itemize}
\item
  DFO Salmon Ontology\ldots{}
\item
  State of Alaska Salmon and People\ldots{}
\item
  Measurement Types in OBIS\ldots{}
\item
  WDFW has definitions of all hatchery escapement data.
  \href{https://wdfw.wa.gov/fishing/management/hatcheries/escapement\#definitions}{Hatchery
  escapement reports \textbar{} Washington Department of Fish \&
  Wildlife}
\item
  Fish Passage Counts has defined metadata that can be used across OFDW
  and WDFW.
  \url{https://www.fpc.org/111_sharedfiles/ColumbiaRiverBasinAdultFishPassageCountsMetadata.pdf}
\end{itemize}

\paragraph{\texorpdfstring{\textbf{Best Practice 5: Store and Analyze
Data in Ways That Others Can Easily Access, Use, and
Trust}}{Best Practice 5: Store and Analyze Data in Ways That Others Can Easily Access, Use, and Trust}}\label{best-practice-5-store-and-analyze-data-in-ways-that-others-can-easily-access-use-and-trust}

Making data easily accessible promotes its use in research and
management, enabling seamless integration with tools and applications.
Ensuring accessible, persistent data storage requires more than just
file hosting. Data should be structured, accessible via API, and stored
in repositories that support long-term preservation.

\subparagraph{Practical Applications:}\label{practical-applications-4}

5.1 Provide Direct Data Access via Application Programming Interfaces
(APIs) using tools such as FastAPI, Flask, or Django REST Framework that
allows users to access, filter, and retrieve data programmatically,
facilitating automation and integration into analytical tools and
decision-support systems

\begin{itemize}
\tightlist
\item
  The Pacific States Marine Fisheries Commission make's their
  \href{https://www.psmfc.org/program/pit-tag-information-systems-ptagis}{PIT
  Tag Information System} data accessible via the
  \href{https://api.ptagis.org/index.html\#:~:text=PTAGIS\%20API\%20Gets\%20a\%20list,PTAGIS\%20and\%20currently\%20contributing\%20data}{PTAGIS
  API}
\end{itemize}

5.2 Archive data in certified long-term, domain-specific repositories
such as the Global Biodiversity Information Facility, the Federated
Research Data Repository (FRDR), or NOAA's NCEI, USGS ScienceBase, or
EMODnet

\begin{itemize}
\tightlist
\item
  TODO
\end{itemize}

5.3 Leverage the integration between GitHub and Zenodo to automate
archiving and DOI assignment, ensuring long-term data preservation.

\paragraph{\texorpdfstring{\textbf{6. Incentivize and Track Data Sharing
and
Reuse}}{6. Incentivize and Track Data Sharing and Reuse}}\label{incentivize-and-track-data-sharing-and-reuse}

The currency of research lies in recognition---credit, citations, and
opportunities for collaboration or co-authorship. Promoting data sharing
requires both cultural and technical infrastructure. The cultural
infrastructure requires a shift towards viewing data publication as
equal in importance to article publication. The infrastructure put in
place needs to support the process of generating citation records that
give credit to all First Nations, Tribes, agencies, and organizations.
By recognizing contributions, tracking reuse, and supporting citation,
data stewards can create a system where sharing is rewarded.

\subparagraph{Practical Applications:}\label{practical-applications-5}

6.1 License data for reuse using liberal licenses

\begin{itemize}
\tightlist
\item
  All data accessible through the \href{https://data.npafc.org}{NPAFC
  data catalogue} is licenced as~
  \href{https://creativecommons.org/licenses/by/4.0/deed.en}{Creative
  Commons Attribution 4.0 International}
\end{itemize}

6.2 Provide recommended citation text and visible credit fields in
metadata

6.3 Create summary dashboards that highlight reuse using
\href{https://www.countermetrics.org/}{COUNTER Code of Practice
compliant metrics} to track dataset views/downloads and the DataCite
APIs

6.4 Ensure that datasets are properly cited in journal articles using in
text citations and the recommended citation in the articles list of
references, not just in a Data Availability statement

\begin{itemize}
\tightlist
\item
  In late 2024, the NPAFC began citing data sets using in-text citations
  and the recommended citation in the list of references with the
  publication of NPAFC Bulletin 7 titled, \emph{Highlights of the 2022
  International Year of the Salmon Pan--Pacific Winter Expedition}.
\end{itemize}

6.5 Promote the view that well documented data publications are primary
research outputs and are significant contributions to the field

\paragraph{\texorpdfstring{\textbf{7. Build Community Through
Co-Development and Mutual
Benefit}}{7. Build Community Through Co-Development and Mutual Benefit}}\label{build-community-through-co-development-and-mutual-benefit}

Creating an infrastructure that standardizes and provides cross-border
and cross-ecosystem data integration is only effective if there's
community engagement. Standards and tools must be co-developed with
their intended users using user-centred design principles (citation
required) to be effective. Engaging biologists, Indigenous stewards, and
data managers ensures relevance, usability, and long-term participation.

\subparagraph{Practical Applications:}\label{practical-applications-6}

7.1 Participate in salmon data focused communities such as the
\href{https://www.rd-alliance.org/groups/salmon-research-and-monitoring-ig/}{Research
Data Alliance's Salmon Research and Monitoring Interest Group}~

7.2 Run participatory workshops for metadata mapping and vocabulary
alignment

\begin{itemize}
\tightlist
\item
  American Fisheries Society 2025 WA-BC Chapter Annual Meeting workshop.
  \href{https://pnamp.org/event/workshop-fishing-for-clarity-knowledge-modeling-to-support-cross-organizational-collaboration-and-data-sharing-about-salmon-escapement/}{'Fishing
  for Clarity: Knowledge Modelling to Support Cross-organizational
  Collaboration and Data Sharing about Salmon Escapement}
\end{itemize}

7.3 Support and follow through on Community Engaged Research
(e.g.~\href{https://salmonprize.com}{The Salmon Prize Project}) that
provides tangible value to the communities in which research or
monitoring was conducted.

\textsubscript{Source:
\href{https://br-johnson.github.io/sdm-paper/appendices/appendix-1-real-world-examples-preview.html\#30b34dea-aa0c-434f-83f6-11e787d2ff9d}{Appendix
1. Real-world Example Applications of the Best Practices}}

\section{}\label{section-1}

\subsection{Appendix 2: Training Roadmap for Salmon Biologists
Transitioning to Data
Stewardship}\label{appendix-2-training-roadmap-for-salmon-biologists-transitioning-to-data-stewardship}

This roadmap outlines essential topics, resources, and learning
materials salmon biologists should engage with to effectively transition
into data stewardship roles. The roadmap follows a structured
progression similar to \href{https://roadmap.sh}{roadmap.sh}.

\subsubsection{1. Foundations of Data
Stewardship}\label{foundations-of-data-stewardship}

\begin{itemize}
\tightlist
\item
  \textbf{Principles:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.go-fair.org/fair-principles/}{FAIR Data
    Principles}
  \item
    \href{https://www.gida-global.org/care}{CARE Principles for
    Indigenous Data Governance}
  \end{itemize}
\item
  \textbf{Seminal Papers:}

  \begin{itemize}
  \tightlist
  \item
    Wilkinson et al.~2016
    \href{https://doi.org/10.1038/sdata.2016.18}{FAIR Guiding
    Principles}
  \item
    Carroll et al.~2019
    \href{https://doi.org/10.5334/dsj-2019-031}{Indigenous Data
    Governance}
  \end{itemize}
\item
  \textbf{Courses and Tutorials:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.go-fair.org/resources/videos/fair-principles-explained/}{FAIR
    Principles Explained (GO-FAIR)}
  \end{itemize}
\end{itemize}

\subsubsection{2. Data Management \&
Governance}\label{data-management-governance}

\begin{itemize}
\tightlist
\item
  \textbf{Seminal Papers and Reports:}

  \begin{itemize}
  \tightlist
  \item
    Plotkin, 2014 \href{https://doi.org/10.1016/c2012-0-07057-3}{Data
    Stewardship}
  \item
    NOAA, 2007 \href{https://doi.org/10.17226/12017}{Environmental Data
    Management}
  \end{itemize}
\item
  \textbf{Practical Tools:}

  \begin{itemize}
  \tightlist
  \item
    Data Management Plan Templates (\href{https://dmptool.org}{DMPTool})
  \item
    DACI and RACI Frameworks
    (\href{https://www.atlassian.com/team-playbook/plays/daci}{Atlassian
    DACI Guide})
  \end{itemize}
\end{itemize}

\subsubsection{3. Metadata Standards and
Ontologies}\label{metadata-standards-and-ontologies}

\begin{itemize}
\tightlist
\item
  \textbf{Standards to Master:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.iso.org/standard/53798.html}{ISO 19115 Metadata
    Standard}
  \item
    \href{https://eml.ecoinformatics.org/}{Ecological Metadata Language
    (EML)}
  \item
    \href{https://dwc.tdwg.org/}{Darwin Core Standard}
  \end{itemize}
\item
  \textbf{Case Studies \& Examples:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://marinedata.psf.ca}{Pacific Salmon Foundation Metadata
    Standards}
  \item
    \href{https://obis.org/dataset/81a9b931-8f47-49c4-94ff-0e46d7e9f1c9}{Hakai
    Institute Juvenile Salmon Program}
  \end{itemize}
\end{itemize}

\subsubsection{4. Controlled Vocabularies \& Persistent Identifiers
(PIDs)}\label{controlled-vocabularies-persistent-identifiers-pids}

\begin{itemize}
\tightlist
\item
  \textbf{PIDs to Implement:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://datacite.org}{DOIs via DataCite}
  \item
    \href{https://orcid.org}{ORCID IDs}
  \item
    \href{https://ror.org}{Research Organization Registry (ROR)}
  \end{itemize}
\item
  \textbf{Practical Guides:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://blog.datacite.org/}{Introduction to PIDs (DataCite
    Blog)}
  \end{itemize}
\end{itemize}

\subsubsection{5. Data Integration \&
Interoperability}\label{data-integration-interoperability}

\begin{itemize}
\tightlist
\item
  \textbf{Seminal Papers:}

  \begin{itemize}
  \tightlist
  \item
    Johnson \& Stap, 2024
    \href{https://doi.org/10.23849/npafcb7/6a4ddpde4}{Salmon Ocean
    Observing System}
  \item
    Bull et al.~2022
    \href{https://doi.org/10.1093/icesjms/fsac099}{Likely Suspects
    Framework}
  \end{itemize}
\item
  \textbf{Technical Skills \& Tools:}

  \begin{itemize}
  \tightlist
  \item
    APIs with \href{https://fastapi.tiangolo.com}{FastAPI},
    \href{https://flask.palletsprojects.com}{Flask},
    \href{https://www.django-rest-framework.org}{Django REST Framework}
  \item
    \href{https://guides.github.com/activities/citable-code/}{Zenodo-GitHub
    Integration}
  \end{itemize}
\end{itemize}

\subsubsection{6. Data Sharing, Citation \&
Metrics}\label{data-sharing-citation-metrics}

\begin{itemize}
\tightlist
\item
  \textbf{Best Practices:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://creativecommons.org/licenses/by/4.0/}{Creative Commons
    Attribution 4.0 International License}
  \end{itemize}
\item
  \textbf{Tracking \& Metrics:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.projectcounter.org/}{COUNTER Metrics}
  \item
    \href{https://datacite.org/service.html}{DataCite API}
  \end{itemize}
\end{itemize}

\subsubsection{7. Community Engagement \&
Co-Development}\label{community-engagement-co-development}

\begin{itemize}
\tightlist
\item
  \textbf{Communities \& Groups:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://rd-alliance.org/groups/salmon-data-management}{Research
    Data Alliance Salmon Research Group}
  \end{itemize}
\item
  \textbf{Approaches \& Frameworks:}

  \begin{itemize}
  \tightlist
  \item
    User-centered Design
    (\href{https://www.interaction-design.org/literature/topics/user-centered-design}{Interaction
    Design Foundation})
  \item
    Community Engaged Research
    (\href{https://www.uvic.ca/research/assets/docs/Community-Engaged-Research.pdf}{University
    of Victoria Guide})
  \end{itemize}
\end{itemize}

\subsubsection{Additional Resources}\label{additional-resources}

\begin{itemize}
\tightlist
\item
  \textbf{Free Courses:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.fosteropenscience.eu/toolkit}{Introduction to Open
    Science (FOSTER)}
  \item
    \href{https://www.coursera.org/learn/data-management}{Research Data
    Management and Sharing (Coursera)}
  \end{itemize}
\item
  \textbf{Blogs \& Websites:}

  \begin{itemize}
  \tightlist
  \item
    \href{https://blog.okfn.org/}{Open Knowledge Foundation Blog}
  \item
    \href{https://www.dataone.org/resources/}{DataONE Data Management
    Resources}
  \end{itemize}
\end{itemize}

This roadmap serves as a structured guide to equip salmon biologists
with the practical and theoretical skills required to excel in data
stewardship roles.

\textsubscript{Source:
\href{https://br-johnson.github.io/sdm-paper/appendices/appendix-2-training-roadmap-preview.html\#58b31dec-16b4-4641-8c4b-057e26e04581}{Appendix
2: Training Roadmap for Salmon Biologists Transitioning to Data
Stewardship}}

\section{}\label{section-2}

\subsection{Appendix 3: Getting Started
Checklist}\label{appendix-3-getting-started-checklist}

\section{Getting Started Checklist for Salmon Data
Stewardship}\label{getting-started-checklist-for-salmon-data-stewardship}

Use this practical checklist to assess how well your project, program,
or organization aligns to the seven Best Practices in index.qmd. Start
at the Project level, then scale to Program and Organization. Check off
items you've completed and note gaps to prioritize.

Tip: For each item, capture a link to the living source (e.g.,
repository, shared drive, policy page) and the responsible owner.

\subsection{Practice 1 --- Make Data Governance
Explicit}\label{practice-1-make-data-governance-explicit}

\begin{itemize}
\tightlist
\item
  Project

  \begin{itemize}
  \tightlist
  \item
    Do you have a lightweight Data Management Plan (DMP) covering scope,
    sensitive data, retention, and sharing? (link)
  \item
    Is there a RACI (Responsible, Accountable, Consulted, Informed)
    table for key tasks? (owner)
  \item
    Are Indigenous Data Sovereignty requirements identified and
    documented (who to consult, approvals needed)?
  \item
    Is a data product charter written for each dataset or analysis
    product with purpose, audience, quality thresholds, release plan?
  \end{itemize}
\item
  Program

  \begin{itemize}
  \tightlist
  \item
    Are DMP and charter templates standardized across projects and
    stored centrally?
  \item
    Are role definitions for Data Steward, Product Owner, and Maintainer
    explicit and assigned for priority datasets?
  \item
    Are data sharing agreements/MOUs and ethical review pathways
    documented and reusable?
  \end{itemize}
\item
  Organization

  \begin{itemize}
  \tightlist
  \item
    Does a governance policy exist that sets minimum requirements for
    DMPs, RACI, retention, IDS, and release reviews?
  \item
    Is there a standing review forum (e.g., monthly data governance
    check‑in) and a registry of governed data products?
  \end{itemize}
\end{itemize}

Evidence to collect: DMP link, data product charter(s), RACI, IDS
guidance, sharing agreements registry.

\subsection{Practice 2 --- Reuse Proven
Infrastructure}\label{practice-2-reuse-proven-infrastructure}

\begin{itemize}
\tightlist
\item
  Project

  \begin{itemize}
  \tightlist
  \item
    Is your code in version control (e.g., Git) with an issue tracker
    and releases?
  \item
    Are you using an approved repository or data store rather than
    creating a new silo? (where)
  \item
    Do you use existing organization authentication/authorization and
    backup processes?
  \end{itemize}
\item
  Program

  \begin{itemize}
  \tightlist
  \item
    Is there a preferred stack list (storage, metadata catalog, workflow
    runner, packaging, container base images)?
  \item
    Do projects consistently deposit finalized data in approved
    repositories with clear intake criteria?
  \end{itemize}
\item
  Organization

  \begin{itemize}
  \tightlist
  \item
    Are enterprise services available and documented (data lake, object
    store, catalog/portal, archival repository)?
  \item
    Is there a deprecation pathway for legacy systems and a migration
    plan for priority datasets?
  \end{itemize}
\end{itemize}

Evidence to collect: repository URLs, infrastructure inventory, intake
criteria, backup/DR documentation.

\subsection{Practice 3 --- Use Persistent Identifiers (PIDs) for People,
Projects, Data, and
Methods}\label{practice-3-use-persistent-identifiers-pids-for-people-projects-data-and-methods}

\begin{itemize}
\tightlist
\item
  Project

  \begin{itemize}
  \tightlist
  \item
    Do all contributors have ORCID IDs recorded in metadata?
  \item
    Does the project have a resolvable PID (e.g., DOI for a project page
    or protocol, internal project ID)?
  \item
    Are datasets assigned DOIs (or other PIDs) at publication, and are
    versions tracked?
  \item
    Are methods/protocols published and citable (e.g., protocol DOI) and
    linked from dataset metadata?
  \end{itemize}
\item
  Program

  \begin{itemize}
  \tightlist
  \item
    Is there guidance on when to mint PIDs, by whom, and where they
    resolve?
  \item
    Are projects linked to organizational identifiers (e.g., ROR for
    institutions) in metadata?
  \end{itemize}
\item
  Organization

  \begin{itemize}
  \tightlist
  \item
    Is there a PID policy and a provider/registrar configured (e.g.,
    DataCite) with a documented workflow?
  \item
    Are PID linkages automated in the catalog (people ↔ projects ↔
    datasets ↔ publications)?
  \end{itemize}
\end{itemize}

Evidence to collect: ORCID list, PID policy, DOI records, resolver links
in the catalog.

\subsection{Practice 4 --- Shared Data Models, Vocabularies, and
Metadata}\label{practice-4-shared-data-models-vocabularies-and-metadata}

\begin{itemize}
\tightlist
\item
  Project

  \begin{itemize}
  \tightlist
  \item
    Which metadata profile is used (e.g., ISO 19115, EML)? Is the
    minimum profile complete and machine‑readable?
  \item
    Are core entities modeled consistently (stock/population IDs,
    locations, temporal coverage, age/brood year semantics)?
  \item
    Are controlled vocabularies/code lists applied for key fields (e.g.,
    species codes, gear, life stage, age type)?
  \item
    Is a data dictionary included with definitions, units, allowed
    values, and provenance for each variable?
  \end{itemize}
\item
  Program

  \begin{itemize}
  \tightlist
  \item
    Do projects use a shared schema and code lists across datasets to
    enable easy joins?
  \item
    Are validation checks in CI (schema validation, vocab checks)
    standardized across repositories?
  \end{itemize}
\item
  Organization

  \begin{itemize}
  \tightlist
  \item
    Is there an endorsed salmon domain profile and shared code lists
    with owners and change control?
  \item
    Are mappings to external standards maintained (e.g., taxonomic,
    geospatial, hydrological registries)?
  \end{itemize}
\end{itemize}

Evidence to collect: metadata profiles, data dictionary, code lists,
schema validators, mapping documentation.

\subsection{Practice 5 --- Store and Analyze Data for Easy Access, Use,
and
Trust}\label{practice-5-store-and-analyze-data-for-easy-access-use-and-trust}

\begin{itemize}
\tightlist
\item
  Project

  \begin{itemize}
  \tightlist
  \item
    Is raw data immutable and separated from processed/analysis outputs?
  \item
    Is there a fully reproducible workflow (scripts/notebooks +
    environment + parameters) that runs end‑to‑end?
  \item
    Is the computational environment captured (lockfile/conda env,
    container image) and versioned?
  \item
    Are QA/QC checks automated with logs and thresholds documented?
  \item
    Are access controls and sensitive data handling documented and
    implemented?
  \end{itemize}
\item
  Program

  \begin{itemize}
  \tightlist
  \item
    Do projects follow a common repo layout and release process (tags,
    changelog, signed artifacts)?
  \item
    Are standard storage classes, lifecycle policies, and archival rules
    applied?
  \end{itemize}
\item
  Organization

  \begin{itemize}
  \tightlist
  \item
    Are security, backup/retention, and audit requirements defined and
    routinely verified?
  \item
    Is there a trusted long‑term archive with fixity checking and
    preservation metadata?
  \end{itemize}
\end{itemize}

Evidence to collect: workflow definition, environment files, container
references, QA/QC reports, storage/backup settings.

\subsection{Practice 6 --- Incentivize and Track Sharing and
Reuse}\label{practice-6-incentivize-and-track-sharing-and-reuse}

\begin{itemize}
\tightlist
\item
  Project

  \begin{itemize}
  \tightlist
  \item
    Is a clear citation and license statement included in metadata and
    README?
  \item
    Are reuse metrics collected (downloads, citations, API hits) and
    reviewed?
  \item
    Do release notes document what changed and implications for users?
  \end{itemize}
\item
  Program

  \begin{itemize}
  \tightlist
  \item
    Are common metrics dashboards available for priority datasets and
    updated automatically?
  \item
    Are data citations tracked in assessments, reports, and staff
    evaluations?
  \end{itemize}
\item
  Organization

  \begin{itemize}
  \tightlist
  \item
    Do policies require citation guidance and permissive, appropriate
    licensing where possible?
  \item
    Are automated reports of reuse (e.g., via DOI provider APIs)
    delivered to product owners and leadership?
  \end{itemize}
\end{itemize}

Evidence to collect: LICENSE, CITATION.cff, reuse dashboard link, policy
excerpts, sample citations in reports.

\subsection{Practice 7 --- Build Community Through Co‑Development and
Mutual
Benefit}\label{practice-7-build-community-through-codevelopment-and-mutual-benefit}

\begin{itemize}
\tightlist
\item
  Project

  \begin{itemize}
  \tightlist
  \item
    Are stakeholders identified, including First
    Nations/Tribes/Indigenous partners, and engagement needs documented?
  \item
    Have you held at least one co‑design session to validate user needs
    and success criteria?
  \item
    Is there an open feedback channel (issues form, contact) and a
    published roadmap?
  \end{itemize}
\item
  Program

  \begin{itemize}
  \tightlist
  \item
    Do cross‑project working groups exist for models, vocabularies, and
    tooling with regular cadence and notes?
  \item
    Are community contributions recognized (authorship,
    acknowledgements, meeting time, funding)?
  \end{itemize}
\item
  Organization

  \begin{itemize}
  \tightlist
  \item
    Is there an endorsed governance body or community of practice with
    decision records?
  \item
    Are procurement/funding mechanisms available to support shared
    components and Indigenous partnerships?
  \end{itemize}
\end{itemize}

Evidence to collect: stakeholder map, engagement records, roadmap,
working group notes, decision log.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Quick Start: 30/60/90‑Day
Plan}\label{quick-start-306090day-plan}

\begin{itemize}
\tightlist
\item
  First 30 days

  \begin{itemize}
  \tightlist
  \item
    Create/standardize DMP + RACI; draft data product charters for top
    1--2 datasets.
  \item
    Move code to version control; document repo structure; capture
    environment file.
  \item
    Choose metadata profile and draft a minimal data dictionary; list
    code lists in use.
  \end{itemize}
\item
  By 60 days

  \begin{itemize}
  \tightlist
  \item
    Mint/plan PIDs (project page/protocols), add ORCIDs to metadata,
    prepare DOI for first dataset.
  \item
    Add schema + vocab validation to CI; separate raw/processed;
    automate QA/QC checks.
  \item
    Stand up a reuse dashboard or basic metrics capture; add
    citation/license to README and metadata.
  \end{itemize}
\item
  By 90 days

  \begin{itemize}
  \tightlist
  \item
    Publish first governed release to approved repository with DOI and
    complete metadata.
  \item
    Formalize cross‑project working group and change control for
    vocabularies.
  \item
    Document archival/retention path and verify backups; schedule
    governance reviews.
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Minimal Artifacts Checklist (Project
Level)}\label{minimal-artifacts-checklist-project-level}

\begin{itemize}
\tightlist
\item
  DMP (with IDS considerations) and RACI
\item
  Data product charter(s) for priority dataset(s)
\item
  Versioned repository with releases and changelog
\item
  Metadata profile file + data dictionary + code lists
\item
  Reproducible workflow + environment file or container
\item
  QA/QC checks and results log
\item
  Citation and license statements
\item
  Plan for PIDs (ORCID list, dataset/protocol DOIs)
\item
  Evidence of stakeholder engagement and roadmap
\end{itemize}

Maintain this list as a living issue in your repository and review
quarterly.

\textsubscript{Source:
\href{https://br-johnson.github.io/sdm-paper/appendices/appendix-3-getting-started-checklist-preview.html\#454edf0c-0379-49db-a45c-ffa3400c9f4c}{Appendix
3: Getting Started Checklist}}




\end{document}
