## Appendix 1. Real-world Example Applications of the Best Practices

Here we provide detailed descriptions of the seven best practices for salmon data stewardship, along with practical applications and real-world examples. This is not an exhaustive list, but rather a starting point for salmon biologists and data stewards to implement effective data stewardship practices in their work based on examples from the salmon research and management community.

#### **1. Make Data Governance Explicit to Support Trust and Reuse**

Clear governance defines roles, responsibilities, and procedures ensuring data quality, long-term maintenance, accountability, and compliance with community principles such as FAIR and CARE. Effective governance fosters trust, facilitates data sharing, and reduces ambiguity regarding decision making, and is critical for coordinating both technical and sociocultural aspects of data stewardship.

In collaborative international or multi-organizational settings, establishing governance at the outset of a project is crucial for aligning diverse groups, including biologists, data managers, Indigenous communities, policymakers, and other participants. Early governance planning should establish clear, collaborative frameworks that respect each group’s expertise and needs from the beginning. 

##### Practical Applications:

1.1 Document roles and responsibilities clearly at project start using a Project or Data Product Governance Charter and structured frameworks (e.g., DACI or RACI charts) that relate to organizational data policies.

-   [Example of a Data Management Plan from the California Department of Water Resources](https://raw.githubusercontent.com/Br-Johnson/sdm-paper/refs/heads/main/examples/Cal_DMP.pdf)

-   [Data Management Plan Templates](https://dmptool.org/public_templates?page=ALL)

1.2 Integrate CARE principles to ensure ethical governance and respect Indigenous data rights.

-   Northwest Indian Fisheries Commission use password protected website to host all the WDFW and tribal data in a one-stop shopping website for co-managers to pull data they need for decision-making process. <https://fisheriesservices.nwifc.org/>

1.3 Create a governance or oversight committee for regular data practice reviews and decision making regarding data structures, timelines, data sharing agreements and interoperability protocols

- Pacific Salmon Commission has formed a Technical Committee on Data Sharing including both US and Canadian data contributors. <https://www.psc.org/membership-lists/>

#### **2. Reuse Proven Infrastructure to Save Time and Increase Interoperability**

Building custom solutions should be avoided where possible. Maximizing existing platforms and technologies reduces costs, accelerates implementation, and increases data interoperability. Building modular, interoperable systems grounded in proven technologies ensures sustainable long-term stewardship.

##### Practical Applications:

2.1 [Use the Ocean Biodiversity Information System or the Global Biodiversity Information Facility to standardize and host your data](https://doi.org/10.14286/duc6mu)

2.2 Use free data catalogue services such as the Knowledge Network for Biocomplexity (KNB) or Zenodo

#### **3. Make Data, People, Projects, and Outputs Discoverable, Linked and Citable with PIDs**

Persistent identifiers (PIDs), including Digital Object Identifiers (DOI) are essential for tracking the provenance and reuse of data, and linking data, protocols, organizations and people. They allow for consistent referencing, integration across systems, and automated credit via data citation.

##### Practical Applications:

3.1 Encourage researchers to register for an [Open Researcher and Contributor ID (ORCID)](https://orcid.org/) and include ORCIDs in metadata records and submission forms

3.2 Register your organization with the Research Organization Registry (ROR) and use ROR IDs to identify institutions involved in salmon science.

3.3 Assign DOIs to data packages, protocols, and reports using DataCite.

3.4 Embed DOIs in dashboards, figures, and metadata so they persist in derivative products.

#### **4. Use Shared Data Models, Vocabularies and Metadata to Enable Integration**

Standardizing metadata and terminology ensures data can be interpreted correctly and integrated across systems. Controlled vocabularies, community ontologies, and structured metadata schemas allow data to retain its full semantic meaning.

##### Practical Applications:

4.1 Configure data catalogues and metadata intake tools to accept Internationally recognized metadata schemas such as ISO 19115, Ecological Metadata Language (EML), or DataCite.

-   The Pacific Salmon Foundation’s data portal asks contributors to provide metadata in ISO 19115 or other standard formats. [[marinedata.psf.ca]{.underline}](https://marinedata.psf.ca/data/data-submission-form/#:~:text=){alt="https://marinedata.psf.ca/data/data-submission-form/#:~:text="}, ensuring consistent metadata structure

4.2 Model datasets and databases using the [Darwin Core Standard](https://dwc.tdwg.org/)

-   The Hakai Institute Juvenile Salmon Program publishes their data to OBIS using Darwin Core: [Hakai Institute Juvenile Salmon Program](https://www.gbif.org/dataset/72de3af4-1572-4f2d-8006-2bfa2007065c)

-   The International Year of the Salmon High Seas Expeditions data moblization efforts [@johnson2024] published their data to OBIS: <https://www.gbif.org/dataset/search?project_id=IYS>

4.3 Re-use or publish data terms that are shared online using a persistent identifier in a controlled vocabulary or ontology

-   DFO Salmon Ontology...

-   State of Alaska Salmon and People...

-   Measurement Types in OBIS...

-   WDFW has definitions of all hatchery escapement data. [Hatchery escapement reports \| Washington Department of Fish & Wildlife](https://wdfw.wa.gov/fishing/management/hatcheries/escapement#definitions)

-   Fish Passage Counts has defined metadata that can be used across OFDW and WDFW. <https://www.fpc.org/111_sharedfiles/ColumbiaRiverBasinAdultFishPassageCountsMetadata.pdf>

#### **Best Practice 5: Store and Analyze Data in Ways That Others Can Easily Access, Use, and Trust**

Making data easily accessible promotes its use in research and management, enabling seamless integration with tools and applications. Ensuring accessible, persistent data storage requires more than just file hosting. Data should be structured, accessible via API, and stored in repositories that support long-term preservation.

##### Practical Applications:

5.1 Provide Direct Data Access via Application Programming Interfaces (APIs) using tools such as FastAPI, Flask, or Django REST Framework that allows users to access, filter, and retrieve data programmatically, facilitating automation and integration into analytical tools and decision-support systems

-   The Pacific States Marine Fisheries Commission make's their [PIT Tag Information System](https://www.psmfc.org/program/pit-tag-information-systems-ptagis) data accessible via the [PTAGIS API](https://api.ptagis.org/index.html#:~:text=PTAGIS%20API%20Gets%20a%20list,PTAGIS%20and%20currently%20contributing%20data)

5.2 Archive data in certified long-term, domain-specific repositories such as the Global Biodiversity Information Facility, the Federated Research Data Repository (FRDR), or NOAA’s NCEI, USGS ScienceBase, or EMODnet

-   TODO

5.3 Leverage the integration between GitHub and Zenodo to automate archiving and DOI assignment, ensuring long-term data preservation.

#### **6. Incentivize and Track Data Sharing and Reuse**

The currency of research lies in recognition—credit, citations, and opportunities for collaboration or co-authorship. Promoting data sharing requires both cultural and technical infrastructure. By recognizing contributions, tracking reuse, and supporting citation, data stewards can create a system where sharing is rewarded.

##### Practical Applications:

6.1 License data for reuse using liberal licenses

-   [Creative Commons Attribution 4.0 International](https://creativecommons.org/licenses/by/4.0/deed.en)

6.2 Provide recommended citation text and visible credit fields in metadata

6.3 Create summary dashboards that highlight reuse using [COUNTER Code of Practice compliant metrics](https://www.countermetrics.org/) to track dataset views/downloads and the DataCite APIs

6.4 Ensure that datasets are properly cited in journal articles using in text citations and the recommended citation in the articles list of references, not just in a Data Availability statement

6.5 Promote the view that well documented data publications are primary research outputs and are significant contributions to the field

#### **7. Build Community Through Co-Development and Mutual Benefit**

Creating an infrastructure that standardizes and provides cross-border and cross-ecosystem data integration is only effective if there’s community engagement. Standards and tools must be co-developed with their intended users using user-centred design principles (citation required) to be effective. Engaging biologists, Indigenous stewards, and data managers ensures relevance, usability, and long-term participation.

##### Practical Applications:

7.1 Participate in salmon data focussed communities such as the [Research Data Alliance’s Salmon Research and Monitoring Interest Group](https://www.rd-alliance.org/groups/salmon-research-and-monitoring-ig/) 

7.2 Run participatory workshops for metadata mapping and vocabulary alignment

7.3 Support and follow through on Community Engaged Research (e.g. [The Salmon Prize Project](https://salmonprize.com)) that provides tangible value to the communities in which research or monitoring was conducted.
